harvard open course
https://nlp.seas.harvard.edu/annotated-transformer/

https://qiyanjun.github.io/2024sp-GenAI-Risk-Benefits/
https://qiyanjun.github.io/2024sp-GenAI-Risk-Benefits//LecturesByTags/

andrei karpathy
https://github.com/karpathy
https://github.com/karpathy/nanoGPT
https://github.com/karpathy/minGPT

Sebastian Raschka
https://github.com/rasbt

UVA, Qi
https://qiyanjun.github.io/2024sp-GenAI-Risk-Benefits/
https://qiyanjun.github.io/2025sp-GenAI-overview//About/


https://bios740.github.io/syllabus/

Foundationa of large language models https://arxiv.org/abs/2501.09223

LensLLM
https://arxiv.org/abs/2505.03793

Understanding machine learning from theory to algorithms, book. 

Yilun Xu: https://yilun-xu.com/
(i) New models: PFGM [10], PFGM++ [13], HGF [18], t-EDM [21]
(ii) Training: STF [11], Disco-Diff [16], Style Control [9]
(iii) Sampling: Restart sampling [14], Particle Guidance [15], Anytime AR [5]
(iv) Discrete diffusion: DDPD [19], EDLM [20]
(v) Diffusion Distillation: TCM [22], f-distill [23]

formal reasoning meets LLM
https://www.youtube.com/live/XuKeSzc7f_c?si=oolwtlAgQPnvXxxV

organoid neuron network
https://www.cell.com/neuron/fulltext/S0896-6273(22)00806-6

virtual lab, AI co-scientists. 
https://www.nature.com/articles/d41586-025-02028-5?utm_source=chatgpt.com

Cell learning
https://ieeexplore.ieee.org/document/9764721
https://mpinb.mpg.de/en/research-groups/groups/cellular-computations-and-learning/news-ccl-eng/koseska-synergygrant-celearn.html

